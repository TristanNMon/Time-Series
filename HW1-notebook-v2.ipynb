{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afb72815-74ef-4b27-b413-26c1c4f20652",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77573173-e7b9-46b4-ae78-a0f9b0d87351",
   "metadata": {},
   "source": [
    "**Imports**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263236fe-6d00-45aa-80f1-e36765758e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from loadmydata.load_human_locomotion import (\n",
    "    load_human_locomotion_dataset,\n",
    "    get_code_list,\n",
    ")\n",
    "\n",
    "rng = np.random.default_rng()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce9a17-6c03-4343-b2d4-c5dc94eac178",
   "metadata": {},
   "source": [
    "**Utility functions**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53469a53-92a0-403d-9bb4-544cd0e7a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = (1 + 5**0.5) / 2  # golden ratio ≈ 1.618\n",
    "\n",
    "\n",
    "def fig_ax(figsize=(phi * 5, 5)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.autoscale(enable=True, axis=\"x\", tight=True)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7389c8-24b0-475f-9fa8-93d117311f52",
   "metadata": {},
   "source": [
    "# Spectral feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbabb4f-0ba7-43a6-80e4-9dab3d914407",
   "metadata": {},
   "source": [
    "## Question 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decfc826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acovf\n",
    "from scipy.signal import periodogram\n",
    "\n",
    "\n",
    "def sim_plot_acov_periodogram():\n",
    "    # simulation parameters\n",
    "    Ns = [200, 500, 1000]\n",
    "    N_sim = 100\n",
    "    fs = 1.0\n",
    "\n",
    "    for N in Ns:\n",
    "        # define max lag\n",
    "        max_lag = N - 1\n",
    "        acovs = np.zeros((N_sim, max_lag + 1))\n",
    "        for s in range(N_sim):\n",
    "            x = rng.normal(0, 1, N)\n",
    "            # compute biased estimate because less variance\n",
    "            ac = acovf(x, demean=False, fft=True, adjusted=False)\n",
    "            acovs[s] = ac[: max_lag + 1]\n",
    "\n",
    "        mu, std = acovs.mean(0), acovs.std(0)\n",
    "        lags = np.arange(max_lag + 1)\n",
    "\n",
    "        fig, ax = fig_ax()\n",
    "        ax.plot(lags, mu, lw=2, label=\"mean\")\n",
    "        ax.fill_between(lags, mu - std, mu + std, alpha=0.25, label=\"±1 std\")\n",
    "        ax.set_title(f\"ACov white noise (N={N}, fs={fs} Hz, {N_sim} runs)\")\n",
    "\n",
    "        plt.xlabel(\"Lag τ\")\n",
    "        plt.ylabel(r\"$\\hat{\\gamma}(\\tau)$\")\n",
    "        plt.grid(alpha=0.4)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        # save figure in figures\n",
    "        plt.savefig(f\"figures/acov_white_noise_N{N}_fs{fs}_sim{N_sim}.png\")\n",
    "        plt.show()\n",
    "\n",
    "    for N in Ns:\n",
    "        f, _ = periodogram(np.zeros(N), fs=fs)\n",
    "        Pxx = np.zeros((N_sim, len(f)))\n",
    "\n",
    "        for s in range(N_sim):\n",
    "            x = rng.normal(0, 1, N)\n",
    "            f, Pxx[s] = periodogram(x, fs=fs, scaling=\"density\", return_onesided=True)\n",
    "            # rescale Pxx because periodogram returns one-sided PSD\n",
    "            Pxx[s] /= 2\n",
    "\n",
    "        mu, std = Pxx.mean(0), Pxx.std(0)\n",
    "\n",
    "        fig, ax = fig_ax()\n",
    "        ax.plot(f, mu, lw=2, label=\"mean\")\n",
    "        ax.fill_between(f, mu - std, mu + std, alpha=0.25, label=\"±1 std\")\n",
    "        ax.set_title(f\"Periodogram of white noise (N={N}, fs={fs} Hz, {N_sim} runs)\")\n",
    "        plt.xlabel(\"Frequency f (Hz)\")\n",
    "        plt.ylabel(\"Power spectral density\")\n",
    "        plt.grid(alpha=0.4)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        # save figure in figures\n",
    "        plt.savefig(f\"figures/periodogram_white_noise_N{N}_fs{fs}_sim{N_sim}.png\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "sim_plot_acov_periodogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e93f8f9-a5f4-4918-b1cb-06dcf94e4282",
   "metadata": {},
   "source": [
    "## Question 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207edbf1-986a-49f2-bf06-2b8a46e58545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_plot_periodogram_bartlett():\n",
    "    Ns = [200, 500, 1000]\n",
    "    N_sim = 100\n",
    "    fs = 1.0\n",
    "    K = 5\n",
    "\n",
    "    for N in Ns:\n",
    "        N_seg = N // K\n",
    "        f, _ = periodogram(np.zeros(N_seg), fs=fs)  # correct frequency grid\n",
    "        Pxx = np.zeros((N_sim, len(f)))\n",
    "\n",
    "        for s in range(N_sim):\n",
    "            x = rng.normal(0, 1, N)\n",
    "            x_segments = np.array_split(x, K)\n",
    "            Pxx_segments = []\n",
    "            for segment in x_segments:\n",
    "                f, Pxx_seg = periodogram(\n",
    "                    segment, fs=fs, scaling=\"density\", return_onesided=True\n",
    "                )\n",
    "                Pxx_seg /= 2  # rescale for one-sided PSD\n",
    "                Pxx_segments.append(Pxx_seg)\n",
    "            Pxx[s] = np.mean(Pxx_segments, axis=0)\n",
    "\n",
    "        mu, std = Pxx.mean(0), Pxx.std(0)\n",
    "\n",
    "        fig, ax = fig_ax()\n",
    "        ax.plot(f, mu, lw=2, label=\"mean\")\n",
    "        ax.fill_between(f, mu - std, mu + std, alpha=0.25, label=\"±1 std\")\n",
    "        ax.set_title(f\"Bartlett Periodogram (N={N}, K={K}, {N_sim} sims)\")\n",
    "        ax.set_xlabel(\"Frequency f (Hz)\")\n",
    "        ax.set_ylabel(\"Power spectral density\")\n",
    "        ax.grid(alpha=0.4)\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        # save figure in figures\n",
    "        plt.savefig(\n",
    "            f\"figures/bartlett_periodogram_white_noise_N{N}_K{K}_fs{fs}_sim{N_sim}.png\"\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "sim_plot_periodogram_bartlett()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf9a94c-244a-470b-b9d6-ce9be480abfa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dynamic time warping (DTW)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dd4390-73c6-47f5-9ddd-2a01bf43d4ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data\n",
    "\n",
    "This data set consists of signals collected with inertial measurement units (accelerometer+gyroscope), from 230 subjects undergoing a fixed protocol:\n",
    "\n",
    "- standing still,\n",
    "- walking 10 m,\n",
    "- turning around,\n",
    "- walking back,\n",
    "- stopping.\n",
    "\n",
    "In this assignment, we only consider the vertical acceleration of the left foot and all signals are truncated to 20 seconds (as a result, they all have same length). Signals are sampled at 100 Hz.\n",
    "\n",
    "The measured population is composed of healthy subjects as well as patients with neurological or orthopedic disorders.\n",
    "\n",
    "The start and end time stamps of thousands of footsteps are available.\n",
    "\n",
    "The data are part of a larger data set described in [1].\n",
    "\n",
    "[1] Truong, C., Barrois-Müller, R., Moreau, T., Provost, C., Vienne-Jumeau, A., Moreau, A., Vidal, P.-P., Vayatis, N., Buffat, S., Yelnik, A., Ricard, D., & Oudre, L. (2019). A data set for the study of human locomotion with inertial measurements units. Image Processing On Line (IPOL), 9.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870017f-15e9-45b6-ae13-905810b89f9f",
   "metadata": {},
   "source": [
    "**The task** is to classify footsteps in healthy/non-healthy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2feb6bf-cced-46a7-b6bf-9c04c2cfbeb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following cell defines the training set `(X_train, y_train)` and testing set `(X_test, y_test)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0255e82c-dd54-4e9e-bea8-50284f2588d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_indexes_train = [95, 619, 441, 149, 951, 803, 214, 34, 37, 630]\n",
    "subset_indexes_test = [683, 259, 59, 387, 634]\n",
    "\n",
    "code_list = get_code_list()\n",
    "\n",
    "X_train = list()  # list of footstep signals\n",
    "y_train = list()  # list of pathologies (the \"labels\")\n",
    "\n",
    "for code in np.take(code_list, subset_indexes_train):\n",
    "    single_trial = load_human_locomotion_dataset(code)\n",
    "    signal = (\n",
    "        single_trial.signal.LAZ.to_numpy()\n",
    "    )  # keeping only one dimension (from the left sensor)\n",
    "    steps = single_trial.left_steps\n",
    "    pathology = single_trial.metadata[\"PathologyGroup\"]\n",
    "    label = 0 if pathology == \"Healthy\" else 1  # 0: healthy, 1: non-healthy\n",
    "    for start, end in steps:\n",
    "        X_train.append(signal[start:end])\n",
    "        y_train.append(label)\n",
    "\n",
    "\n",
    "X_test = list()  # list of footstep signals\n",
    "y_test = list()  # list of pathologies (the \"labels\")\n",
    "\n",
    "for code in np.take(code_list, subset_indexes_test):\n",
    "    single_trial = load_human_locomotion_dataset(code)\n",
    "    signal = (\n",
    "        single_trial.signal.LAZ.to_numpy()\n",
    "    )  # keeping only one dimension (from the left sensor)\n",
    "    steps = single_trial.left_steps\n",
    "    pathology = single_trial.metadata[\"PathologyGroup\"]\n",
    "    label = 0 if pathology == \"Healthy\" else 1  # 0: healthy, 1: non-healthy\n",
    "    for start, end in steps:\n",
    "        X_test.append(signal[start:end])\n",
    "        y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df608c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25264b9-5970-49db-8171-bdd32d9b4134",
   "metadata": {},
   "source": [
    "## Question 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f90fd4-aaa7-43bc-94ee-912341dbcc91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78fe3993-ace3-4bb7-8132-1f2cc96c0edf",
   "metadata": {},
   "source": [
    "## Question 11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52310cc2-bd01-45a4-9fa1-0891be2d5691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
